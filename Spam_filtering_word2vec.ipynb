{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zr9M2uh9EzYP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "cfoXh2SkK86m",
    "outputId": "eca59964-cb43-44b1-b51d-9ea9a3245861"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('email.csv')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBRCROMELk0S",
    "outputId": "abc263a5-b729-4aad-bc34-3479fe48e590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwSeukVGL1JK",
    "outputId": "0afc4230-bcef-4319-dc82-b3047066ec84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'spam'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVsJU33hMBji"
   },
   "outputs": [],
   "source": [
    "#check for duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2C6wnOSaMLe-",
    "outputId": "62b09f9d-23d9-4da6-ae89-a8b69b754676"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NO7hGRqMOVef",
    "outputId": "3be8d048-d619-41f1-a637-532c099c62b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "spam    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the number of missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cyTZFaLOvtr",
    "outputId": "82f1a5ab-79ab-4361-cbd2-cabcaa0ded8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xueweisun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download the stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFbl3cdnPu-4"
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "  #remove punctation\n",
    "  nopunc = [char for char in text if char not in string.punctuation]\n",
    "  nopunc = ''.join(nopunc)\n",
    "\n",
    "  #remove stopwords\n",
    "  clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "  return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFcycT8DVfp8",
    "outputId": "8ccd1973-60f9-42c4-bfb6-603be4610501"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Subject, naturally, irresistible, corporate, ...\n",
       "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
       "2    [Subject, unbelievable, new, homes, made, easy...\n",
       "3    [Subject, 4, color, printing, special, request...\n",
       "4    [Subject, money, get, software, cds, software,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the tokenization (a list of tokens also lemmas)\n",
    "df['text'].head().apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UiO9iWPf1su"
   },
   "outputs": [],
   "source": [
    "#get the tokenization(a list of tokens also lemmas)\n",
    "text=df['text'].head().apply(process_text)\n",
    "import smart_open\n",
    "smart_open.open = smart_open.smart_open\n",
    "from gensim.models import Word2Vec\n",
    "#build the word2vec model\n",
    "model_word2vec= Word2Vec(window=10, min_count=2, size=100,workers=4)\n",
    "#build vocabulary from a sequence of sentences\n",
    "model_word2vec.build_vocab(text,progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt0F62NGf1su",
    "outputId": "2697b9f9-4e05-47e7-e3b7-fbdd807b9924"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get epochs to avoid common mistakes around the modelâ€™s ability to do multiple training passes itself\n",
    "model_word2vec.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEq82yyNf1sv",
    "outputId": "a01dd8f7-74de-416c-c7a5-1da495e9fbc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 1485)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the word2vec model\n",
    "model_word2vec.train(text,total_examples=model_word2vec.corpus_count,epochs=model_word2vec.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-22RHZSf1sv",
    "outputId": "7e2ba354-615e-4417-ff08-cb6f47dee705"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "#save the word2vec model \n",
    "model_word2vec.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9EUns_Hf1sw",
    "outputId": "f94c56b3-9702-4609-d371-36ec545fb6ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.485879</td>\n",
       "      <td>-0.422665</td>\n",
       "      <td>0.259873</td>\n",
       "      <td>-0.063737</td>\n",
       "      <td>-0.351703</td>\n",
       "      <td>-0.310604</td>\n",
       "      <td>0.343882</td>\n",
       "      <td>0.285293</td>\n",
       "      <td>0.359695</td>\n",
       "      <td>-0.408639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106639</td>\n",
       "      <td>0.504653</td>\n",
       "      <td>-0.274965</td>\n",
       "      <td>0.216136</td>\n",
       "      <td>0.105973</td>\n",
       "      <td>0.419280</td>\n",
       "      <td>0.031760</td>\n",
       "      <td>0.451890</td>\n",
       "      <td>0.487262</td>\n",
       "      <td>0.553028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.216910</td>\n",
       "      <td>-0.188690</td>\n",
       "      <td>0.116015</td>\n",
       "      <td>-0.028454</td>\n",
       "      <td>-0.157010</td>\n",
       "      <td>-0.138662</td>\n",
       "      <td>0.153519</td>\n",
       "      <td>0.127363</td>\n",
       "      <td>0.160578</td>\n",
       "      <td>-0.182428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047607</td>\n",
       "      <td>0.225292</td>\n",
       "      <td>-0.122752</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>0.047310</td>\n",
       "      <td>0.187179</td>\n",
       "      <td>0.014179</td>\n",
       "      <td>0.201736</td>\n",
       "      <td>0.217528</td>\n",
       "      <td>0.246887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.156175</td>\n",
       "      <td>-0.135857</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>-0.020487</td>\n",
       "      <td>-0.113047</td>\n",
       "      <td>-0.099837</td>\n",
       "      <td>0.110534</td>\n",
       "      <td>0.091701</td>\n",
       "      <td>0.115616</td>\n",
       "      <td>-0.131348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034277</td>\n",
       "      <td>0.162210</td>\n",
       "      <td>-0.088381</td>\n",
       "      <td>0.069472</td>\n",
       "      <td>0.034063</td>\n",
       "      <td>0.134769</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>0.145250</td>\n",
       "      <td>0.156620</td>\n",
       "      <td>0.177759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.138823</td>\n",
       "      <td>-0.120761</td>\n",
       "      <td>0.074249</td>\n",
       "      <td>-0.018211</td>\n",
       "      <td>-0.100487</td>\n",
       "      <td>-0.088744</td>\n",
       "      <td>0.098252</td>\n",
       "      <td>0.081512</td>\n",
       "      <td>0.102770</td>\n",
       "      <td>-0.116754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030468</td>\n",
       "      <td>0.144187</td>\n",
       "      <td>-0.078561</td>\n",
       "      <td>0.061753</td>\n",
       "      <td>0.030278</td>\n",
       "      <td>0.119794</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.129111</td>\n",
       "      <td>0.139218</td>\n",
       "      <td>0.158008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.104117</td>\n",
       "      <td>-0.090571</td>\n",
       "      <td>0.055687</td>\n",
       "      <td>-0.013658</td>\n",
       "      <td>-0.075365</td>\n",
       "      <td>-0.066558</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>0.061134</td>\n",
       "      <td>0.077077</td>\n",
       "      <td>-0.087565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022851</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>-0.058921</td>\n",
       "      <td>0.046315</td>\n",
       "      <td>0.022709</td>\n",
       "      <td>0.089846</td>\n",
       "      <td>0.006806</td>\n",
       "      <td>0.096833</td>\n",
       "      <td>0.104413</td>\n",
       "      <td>0.118506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.485879 -0.422665  0.259873 -0.063737 -0.351703 -0.310604  0.343882   \n",
       "1  0.216910 -0.188690  0.116015 -0.028454 -0.157010 -0.138662  0.153519   \n",
       "2  0.156175 -0.135857  0.083531 -0.020487 -0.113047 -0.099837  0.110534   \n",
       "3  0.138823 -0.120761  0.074249 -0.018211 -0.100487 -0.088744  0.098252   \n",
       "4  0.104117 -0.090571  0.055687 -0.013658 -0.075365 -0.066558  0.073689   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.285293  0.359695 -0.408639  ... -0.106639  0.504653 -0.274965  0.216136   \n",
       "1  0.127363  0.160578 -0.182428  ... -0.047607  0.225292 -0.122752  0.096489   \n",
       "2  0.091701  0.115616 -0.131348  ... -0.034277  0.162210 -0.088381  0.069472   \n",
       "3  0.081512  0.102770 -0.116754  ... -0.030468  0.144187 -0.078561  0.061753   \n",
       "4  0.061134  0.077077 -0.087565  ... -0.022851  0.108140 -0.058921  0.046315   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.105973  0.419280  0.031760  0.451890  0.487262  0.553028  \n",
       "1  0.047310  0.187179  0.014179  0.201736  0.217528  0.246887  \n",
       "2  0.034063  0.134769  0.010209  0.145250  0.156620  0.177759  \n",
       "3  0.030278  0.119794  0.009074  0.129111  0.139218  0.158008  \n",
       "4  0.022709  0.089846  0.006806  0.096833  0.104413  0.118506  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the tokens of sentences\n",
    "def to_review_vector(text):\n",
    "    global word_vec\n",
    "    \n",
    "    word_vec=np.zeros((1,100))\n",
    " #add word vectors and calculate the mean to get vectors of sentences   \n",
    "    for word in text:\n",
    "        if word in model_word2vec:\n",
    "            word_vec+=np.array([model_word2vec[word]])\n",
    "    return pd.Series(word_vec.mean(axis=0))\n",
    "#use the defined function in the actual dataset\n",
    "messages_bow2=df.text.apply(to_review_vector)\n",
    "messages_bow2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLkI0CXSf1sw"
   },
   "outputs": [],
   "source": [
    "#split data %80 training %20 test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages_bow2, df['spam'],test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHEip6Osf1sw",
    "outputId": "79379a10-2e3e-4a00-914d-de364cc59acd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build a neural network model and use the training data to fit the model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHycH7CFf1sx"
   },
   "outputs": [],
   "source": [
    "#use the model to predict the results of training data\n",
    "pred_train=dict()\n",
    "pred_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrOOHes2f1sx",
    "outputId": "777c4a77-39ef-438c-8617-46199f40b24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3457\n",
      "           1       0.00      0.00      0.00      1099\n",
      "\n",
      "    accuracy                           0.76      4556\n",
      "   macro avg       0.38      0.50      0.43      4556\n",
      "weighted avg       0.58      0.76      0.65      4556\n",
      "\n",
      "Accuracy:  0.7587796312554873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#evaluate on training data based on the built model \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_train,pred_train))\n",
    "print('Accuracy: ', accuracy_score(y_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwrMAY4of1sy"
   },
   "outputs": [],
   "source": [
    "#use the model to predict the results of the testing data\n",
    "prediction = dict()\n",
    "prediction[\"NN\"] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0oFBQhsf1sy",
    "outputId": "66582164-20df-4b9d-9c5c-146a511117b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87       870\n",
      "           1       0.00      0.00      0.00       269\n",
      "\n",
      "    accuracy                           0.76      1139\n",
      "   macro avg       0.38      0.50      0.43      1139\n",
      "weighted avg       0.58      0.76      0.66      1139\n",
      "\n",
      "Confusion Matrix: /n [[870   0]\n",
      " [269   0]]\n"
     ]
    }
   ],
   "source": [
    "#evaluate the neural network model on testing data\n",
    "print(classification_report(y_test,prediction[\"NN\"]))\n",
    "accuracy_score(y_test,prediction[\"NN\"])\n",
    "\n",
    "print('Confusion Matrix: /n', confusion_matrix(y_test,prediction[\"NN\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYlxRSNgf1sy",
    "outputId": "ea127543-0caa-4847-e2b4-8e096f973a86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Cross Validation is : 75.94381035996489  %\n"
     ]
    }
   ],
   "source": [
    "#get accuracy using Cross Validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kfold = KFold(n_splits=5,shuffle=True)\n",
    "print(\"Accuracy using Cross Validation is :\",np.mean(cross_val_score(model,messages_bow2,df['spam'],cv=kfold,scoring=\"accuracy\"))*100,\" %\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Spam filtering_word2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
